initSidebarItems({"constant":[["AVCodecID_AV_CODEC_ID_DVD_SUBTITLE",""],["AVCodecID_AV_CODEC_ID_PCM_S16LE",""],["AVCodecID_AV_CODEC_ID_TTF",""],["AVCodecID_AV_CODEC_ID_VIMA",""],["AVColorPrimaries_AVCOL_PRI_SMPTEST428_1",""],["AVColorSpace_AVCOL_SPC_YCOCG",""],["AVColorTransferCharacteristic_AVCOL_TRC_SMPTEST2084",""],["AVColorTransferCharacteristic_AVCOL_TRC_SMPTEST428_1",""],["AVERROR_EAGAIN",""],["AVERROR_EOF",""],["AVERROR_EXPERIMENTAL",""],["AVERROR_INPUT_CHANGED",""],["AVERROR_OUTPUT_CHANGED",""],["AVFMTCTX_NOHEADER",""],["AVFMT_ALLOW_FLUSH",""],["AVFMT_AVOID_NEG_TS_AUTO",""],["AVFMT_AVOID_NEG_TS_MAKE_NON_NEGATIVE",""],["AVFMT_AVOID_NEG_TS_MAKE_ZERO",""],["AVFMT_EVENT_FLAG_METADATA_UPDATED",""],["AVFMT_FLAG_AUTO_BSF",""],["AVFMT_FLAG_BITEXACT",""],["AVFMT_FLAG_CUSTOM_IO",""],["AVFMT_FLAG_DISCARD_CORRUPT",""],["AVFMT_FLAG_FAST_SEEK",""],["AVFMT_FLAG_FLUSH_PACKETS",""],["AVFMT_FLAG_GENPTS",""],["AVFMT_FLAG_IGNDTS",""],["AVFMT_FLAG_IGNIDX",""],["AVFMT_FLAG_KEEP_SIDE_DATA",""],["AVFMT_FLAG_MP4A_LATM",""],["AVFMT_FLAG_NOBUFFER",""],["AVFMT_FLAG_NOFILLIN",""],["AVFMT_FLAG_NONBLOCK",""],["AVFMT_FLAG_NOPARSE",""],["AVFMT_FLAG_PRIV_OPT",""],["AVFMT_FLAG_SHORTEST",""],["AVFMT_FLAG_SORT_DTS",""],["AVFMT_GENERIC_INDEX",""],["AVFMT_GLOBALHEADER",""],["AVFMT_NEEDNUMBER",""],["AVFMT_NOBINSEARCH",""],["AVFMT_NODIMENSIONS",""],["AVFMT_NOFILE",""],["AVFMT_NOGENSEARCH",""],["AVFMT_NOSTREAMS",""],["AVFMT_NOTIMESTAMPS",""],["AVFMT_NO_BYTE_SEEK",""],["AVFMT_RAWPICTURE",""],["AVFMT_SEEK_TO_PTS",""],["AVFMT_SHOW_IDS",""],["AVFMT_TS_DISCONT",""],["AVFMT_TS_NEGATIVE",""],["AVFMT_TS_NONSTRICT",""],["AVFMT_VARIABLE_FPS",""],["AVINDEX_DISCARD_FRAME",""],["AVINDEX_KEYFRAME",""],["AVIO_FLAG_DIRECT",""],["AVIO_FLAG_NONBLOCK",""],["AVIO_FLAG_READ",""],["AVIO_FLAG_READ_WRITE",""],["AVIO_FLAG_WRITE",""],["AVIO_SEEKABLE_NORMAL",""],["AVIO_SEEKABLE_TIME",""],["AVPALETTE_COUNT",""],["AVPALETTE_SIZE",""],["AVPROBE_PADDING_SIZE",""],["AVPROBE_SCORE_EXTENSION",""],["AVPROBE_SCORE_MAX",""],["AVPROBE_SCORE_MIME",""],["AVPixelFormat_AV_PIX_FMT_GBR24P",""],["AVPixelFormat_AV_PIX_FMT_GRAY8A",""],["AVPixelFormat_AV_PIX_FMT_VAAPI",""],["AVPixelFormat_AV_PIX_FMT_XVMC",""],["AVPixelFormat_AV_PIX_FMT_Y400A",""],["AVSEEK_FLAG_ANY",""],["AVSEEK_FLAG_BACKWARD",""],["AVSEEK_FLAG_BYTE",""],["AVSEEK_FLAG_FRAME",""],["AVSEEK_FORCE",""],["AVSEEK_SIZE",""],["AVSTREAM_EVENT_FLAG_METADATA_UPDATED",""],["AVSTREAM_INIT_IN_INIT_OUTPUT",""],["AVSTREAM_INIT_IN_WRITE_HEADER",""],["AV_BUFFER_FLAG_READONLY",""],["AV_CH_BACK_CENTER",""],["AV_CH_BACK_LEFT",""],["AV_CH_BACK_RIGHT",""],["AV_CH_FRONT_CENTER",""],["AV_CH_FRONT_LEFT",""],["AV_CH_FRONT_LEFT_OF_CENTER",""],["AV_CH_FRONT_RIGHT",""],["AV_CH_FRONT_RIGHT_OF_CENTER",""],["AV_CH_LAYOUT_2POINT1",""],["AV_CH_LAYOUT_2_1",""],["AV_CH_LAYOUT_2_2",""],["AV_CH_LAYOUT_3POINT1",""],["AV_CH_LAYOUT_4POINT0",""],["AV_CH_LAYOUT_4POINT1",""],["AV_CH_LAYOUT_5POINT0",""],["AV_CH_LAYOUT_5POINT0_BACK",""],["AV_CH_LAYOUT_5POINT1",""],["AV_CH_LAYOUT_5POINT1_BACK",""],["AV_CH_LAYOUT_6POINT0",""],["AV_CH_LAYOUT_6POINT0_FRONT",""],["AV_CH_LAYOUT_6POINT1",""],["AV_CH_LAYOUT_6POINT1_BACK",""],["AV_CH_LAYOUT_6POINT1_FRONT",""],["AV_CH_LAYOUT_7POINT0",""],["AV_CH_LAYOUT_7POINT0_FRONT",""],["AV_CH_LAYOUT_7POINT1",""],["AV_CH_LAYOUT_7POINT1_WIDE",""],["AV_CH_LAYOUT_7POINT1_WIDE_BACK",""],["AV_CH_LAYOUT_HEXADECAGONAL",""],["AV_CH_LAYOUT_HEXAGONAL",""],["AV_CH_LAYOUT_MONO",""],["AV_CH_LAYOUT_NATIVE",""],["AV_CH_LAYOUT_OCTAGONAL",""],["AV_CH_LAYOUT_QUAD",""],["AV_CH_LAYOUT_STEREO",""],["AV_CH_LAYOUT_STEREO_DOWNMIX",""],["AV_CH_LAYOUT_SURROUND",""],["AV_CH_LOW_FREQUENCY",""],["AV_CH_LOW_FREQUENCY_2",""],["AV_CH_SIDE_LEFT",""],["AV_CH_SIDE_RIGHT",""],["AV_CH_STEREO_LEFT",""],["AV_CH_STEREO_RIGHT",""],["AV_CH_SURROUND_DIRECT_LEFT",""],["AV_CH_SURROUND_DIRECT_RIGHT",""],["AV_CH_TOP_BACK_CENTER",""],["AV_CH_TOP_BACK_LEFT",""],["AV_CH_TOP_BACK_RIGHT",""],["AV_CH_TOP_CENTER",""],["AV_CH_TOP_FRONT_CENTER",""],["AV_CH_TOP_FRONT_LEFT",""],["AV_CH_TOP_FRONT_RIGHT",""],["AV_CH_WIDE_LEFT",""],["AV_CH_WIDE_RIGHT",""],["AV_CODEC_CAP_AUTO_THREADS",""],["AV_CODEC_CAP_AVOID_PROBING",""],["AV_CODEC_CAP_CHANNEL_CONF",""],["AV_CODEC_CAP_DELAY",""],["AV_CODEC_CAP_DR1",""],["AV_CODEC_CAP_DRAW_HORIZ_BAND",""],["AV_CODEC_CAP_EXPERIMENTAL",""],["AV_CODEC_CAP_FRAME_THREADS",""],["AV_CODEC_CAP_HWACCEL_VDPAU",""],["AV_CODEC_CAP_INTRA_ONLY",""],["AV_CODEC_CAP_LOSSLESS",""],["AV_CODEC_CAP_PARAM_CHANGE",""],["AV_CODEC_CAP_SLICE_THREADS",""],["AV_CODEC_CAP_SMALL_LAST_FRAME",""],["AV_CODEC_CAP_SUBFRAMES",""],["AV_CODEC_CAP_TRUNCATED",""],["AV_CODEC_CAP_VARIABLE_FRAME_SIZE",""],["AV_CODEC_FLAG2_CHUNKS",""],["AV_CODEC_FLAG2_DROP_FRAME_TIMECODE",""],["AV_CODEC_FLAG2_EXPORT_MVS",""],["AV_CODEC_FLAG2_FAST",""],["AV_CODEC_FLAG2_IGNORE_CROP",""],["AV_CODEC_FLAG2_LOCAL_HEADER",""],["AV_CODEC_FLAG2_NO_OUTPUT",""],["AV_CODEC_FLAG2_RO_FLUSH_NOOP",""],["AV_CODEC_FLAG2_SHOW_ALL",""],["AV_CODEC_FLAG2_SKIP_MANUAL",""],["AV_CODEC_FLAG_4MV",""],["AV_CODEC_FLAG_AC_PRED",""],["AV_CODEC_FLAG_BITEXACT",""],["AV_CODEC_FLAG_CLOSED_GOP",""],["AV_CODEC_FLAG_GLOBAL_HEADER",""],["AV_CODEC_FLAG_GRAY",""],["AV_CODEC_FLAG_INTERLACED_DCT",""],["AV_CODEC_FLAG_INTERLACED_ME",""],["AV_CODEC_FLAG_LOOP_FILTER",""],["AV_CODEC_FLAG_LOW_DELAY",""],["AV_CODEC_FLAG_OUTPUT_CORRUPT",""],["AV_CODEC_FLAG_PASS1",""],["AV_CODEC_FLAG_PASS2",""],["AV_CODEC_FLAG_PSNR",""],["AV_CODEC_FLAG_QPEL",""],["AV_CODEC_FLAG_QSCALE",""],["AV_CODEC_FLAG_TRUNCATED",""],["AV_CODEC_FLAG_UNALIGNED",""],["AV_CODEC_PROP_BITMAP_SUB",""],["AV_CODEC_PROP_INTRA_ONLY",""],["AV_CODEC_PROP_LOSSLESS",""],["AV_CODEC_PROP_LOSSY",""],["AV_CODEC_PROP_REORDER",""],["AV_CODEC_PROP_TEXT_SUB",""],["AV_CPU_FLAG_3DNOW",""],["AV_CPU_FLAG_3DNOWEXT",""],["AV_CPU_FLAG_AESNI",""],["AV_CPU_FLAG_ALTIVEC",""],["AV_CPU_FLAG_ARMV5TE",""],["AV_CPU_FLAG_ARMV6",""],["AV_CPU_FLAG_ARMV6T2",""],["AV_CPU_FLAG_ARMV8",""],["AV_CPU_FLAG_ATOM",""],["AV_CPU_FLAG_AVX",""],["AV_CPU_FLAG_AVX2",""],["AV_CPU_FLAG_AVXSLOW",""],["AV_CPU_FLAG_BMI1",""],["AV_CPU_FLAG_BMI2",""],["AV_CPU_FLAG_CMOV",""],["AV_CPU_FLAG_FMA3",""],["AV_CPU_FLAG_FMA4",""],["AV_CPU_FLAG_FORCE",""],["AV_CPU_FLAG_MMX",""],["AV_CPU_FLAG_MMX2",""],["AV_CPU_FLAG_MMXEXT",""],["AV_CPU_FLAG_NEON",""],["AV_CPU_FLAG_POWER8",""],["AV_CPU_FLAG_SETEND",""],["AV_CPU_FLAG_SSE",""],["AV_CPU_FLAG_SSE2",""],["AV_CPU_FLAG_SSE2SLOW",""],["AV_CPU_FLAG_SSE3",""],["AV_CPU_FLAG_SSE3SLOW",""],["AV_CPU_FLAG_SSE4",""],["AV_CPU_FLAG_SSE42",""],["AV_CPU_FLAG_SSSE3",""],["AV_CPU_FLAG_SSSE3SLOW",""],["AV_CPU_FLAG_VFP",""],["AV_CPU_FLAG_VFPV3",""],["AV_CPU_FLAG_VFP_VM",""],["AV_CPU_FLAG_VSX",""],["AV_CPU_FLAG_XOP",""],["AV_DICT_APPEND",""],["AV_DICT_DONT_OVERWRITE",""],["AV_DICT_DONT_STRDUP_KEY",""],["AV_DICT_DONT_STRDUP_VAL",""],["AV_DICT_IGNORE_SUFFIX",""],["AV_DICT_MATCH_CASE",""],["AV_DICT_MULTIKEY",""],["AV_DISPOSITION_ATTACHED_PIC",""],["AV_DISPOSITION_CAPTIONS",""],["AV_DISPOSITION_CLEAN_EFFECTS",""],["AV_DISPOSITION_COMMENT",""],["AV_DISPOSITION_DEFAULT",""],["AV_DISPOSITION_DESCRIPTIONS",""],["AV_DISPOSITION_DUB",""],["AV_DISPOSITION_FORCED",""],["AV_DISPOSITION_HEARING_IMPAIRED",""],["AV_DISPOSITION_KARAOKE",""],["AV_DISPOSITION_LYRICS",""],["AV_DISPOSITION_METADATA",""],["AV_DISPOSITION_ORIGINAL",""],["AV_DISPOSITION_TIMED_THUMBNAILS",""],["AV_DISPOSITION_VISUAL_IMPAIRED",""],["AV_EF_AGGRESSIVE",""],["AV_EF_BITSTREAM",""],["AV_EF_BUFFER",""],["AV_EF_CAREFUL",""],["AV_EF_COMPLIANT",""],["AV_EF_CRCCHECK",""],["AV_EF_EXPLODE",""],["AV_EF_IGNORE_ERR",""],["AV_ERROR_MAX_STRING_SIZE",""],["AV_FOURCC_MAX_STRING_SIZE",""],["AV_FRAME_FILENAME_FLAGS_MULTIPLE",""],["AV_FRAME_FLAG_CORRUPT",""],["AV_FRAME_FLAG_DISCARD",""],["AV_GET_BUFFER_FLAG_REF",""],["AV_HAVE_BIGENDIAN",""],["AV_HAVE_FAST_UNALIGNED",""],["AV_HWACCEL_FLAG_ALLOW_HIGH_DEPTH",""],["AV_HWACCEL_FLAG_IGNORE_LEVEL",""],["AV_INPUT_BUFFER_MIN_SIZE",""],["AV_INPUT_BUFFER_PADDING_SIZE",""],["AV_LOG_DEBUG",""],["AV_LOG_ERROR",""],["AV_LOG_FATAL",""],["AV_LOG_INFO",""],["AV_LOG_MAX_OFFSET",""],["AV_LOG_PANIC",""],["AV_LOG_PRINT_LEVEL",""],["AV_LOG_QUIET",""],["AV_LOG_SKIP_REPEATED",""],["AV_LOG_TRACE",""],["AV_LOG_VERBOSE",""],["AV_LOG_WARNING",""],["AV_NUM_DATA_POINTERS",""],["AV_PARSER_PTS_NB",""],["AV_PIX_FMT_FLAG_ALPHA",""],["AV_PIX_FMT_FLAG_BAYER",""],["AV_PIX_FMT_FLAG_BE",""],["AV_PIX_FMT_FLAG_BITSTREAM",""],["AV_PIX_FMT_FLAG_HWACCEL",""],["AV_PIX_FMT_FLAG_PAL",""],["AV_PIX_FMT_FLAG_PLANAR",""],["AV_PIX_FMT_FLAG_PSEUDOPAL",""],["AV_PIX_FMT_FLAG_RGB",""],["AV_PKT_FLAG_CORRUPT",""],["AV_PKT_FLAG_DISCARD",""],["AV_PKT_FLAG_KEY",""],["AV_PROGRAM_RUNNING",""],["AV_PTS_WRAP_ADD_OFFSET",""],["AV_PTS_WRAP_IGNORE",""],["AV_PTS_WRAP_SUB_OFFSET",""],["AV_SUBTITLE_FLAG_FORCED",""],["AV_TIME_BASE",""],["AV_TS_MAX_STRING_SIZE",""],["FF_API_R_FRAME_RATE",""],["FF_ASPECT_EXTENDED",""],["FF_BUG_AC_VLC",""],["FF_BUG_AMV",""],["FF_BUG_AUTODETECT",""],["FF_BUG_DC_CLIP",""],["FF_BUG_DIRECT_BLOCKSIZE",""],["FF_BUG_EDGE",""],["FF_BUG_HPEL_CHROMA",""],["FF_BUG_IEDGE",""],["FF_BUG_MS",""],["FF_BUG_NO_PADDING",""],["FF_BUG_OLD_MSMPEG4",""],["FF_BUG_QPEL_CHROMA",""],["FF_BUG_QPEL_CHROMA2",""],["FF_BUG_STD_QPEL",""],["FF_BUG_TRUNCATED",""],["FF_BUG_UMP4",""],["FF_BUG_XVID_ILACE",""],["FF_CMP_BIT",""],["FF_CMP_CHROMA",""],["FF_CMP_DCT",""],["FF_CMP_DCT264",""],["FF_CMP_DCTMAX",""],["FF_CMP_MEDIAN_SAD",""],["FF_CMP_NSSE",""],["FF_CMP_PSNR",""],["FF_CMP_RD",""],["FF_CMP_SAD",""],["FF_CMP_SATD",""],["FF_CMP_SSE",""],["FF_CMP_VSAD",""],["FF_CMP_VSSE",""],["FF_CMP_W53",""],["FF_CMP_W97",""],["FF_CMP_ZERO",""],["FF_CODEC_PROPERTY_CLOSED_CAPTIONS",""],["FF_CODEC_PROPERTY_LOSSLESS",""],["FF_CODER_TYPE_AC",""],["FF_CODER_TYPE_DEFLATE",""],["FF_CODER_TYPE_RAW",""],["FF_CODER_TYPE_RLE",""],["FF_CODER_TYPE_VLC",""],["FF_COMPLIANCE_EXPERIMENTAL",""],["FF_COMPLIANCE_NORMAL",""],["FF_COMPLIANCE_STRICT",""],["FF_COMPLIANCE_UNOFFICIAL",""],["FF_COMPLIANCE_VERY_STRICT",""],["FF_COMPRESSION_DEFAULT",""],["FF_DCT_ALTIVEC",""],["FF_DCT_AUTO",""],["FF_DCT_FAAN",""],["FF_DCT_FASTINT",""],["FF_DCT_INT",""],["FF_DCT_MMX",""],["FF_DEBUG_BITSTREAM",""],["FF_DEBUG_BUFFERS",""],["FF_DEBUG_BUGS",""],["FF_DEBUG_DCT_COEFF",""],["FF_DEBUG_ER",""],["FF_DEBUG_GREEN_MD",""],["FF_DEBUG_MB_TYPE",""],["FF_DEBUG_MMCO",""],["FF_DEBUG_MV",""],["FF_DEBUG_NOMC",""],["FF_DEBUG_PICT_INFO",""],["FF_DEBUG_PTS",""],["FF_DEBUG_QP",""],["FF_DEBUG_RC",""],["FF_DEBUG_SKIP",""],["FF_DEBUG_STARTCODE",""],["FF_DEBUG_THREADS",""],["FF_DEBUG_VIS_MB_TYPE",""],["FF_DEBUG_VIS_MV_B_BACK",""],["FF_DEBUG_VIS_MV_B_FOR",""],["FF_DEBUG_VIS_MV_P_FOR",""],["FF_DEBUG_VIS_QP",""],["FF_DECODE_ERROR_INVALID_BITSTREAM",""],["FF_DECODE_ERROR_MISSING_REFERENCE",""],["FF_DEFAULT_QUANT_BIAS",""],["FF_DTG_AFD_14_9",""],["FF_DTG_AFD_16_9",""],["FF_DTG_AFD_16_9_SP_14_9",""],["FF_DTG_AFD_4_3",""],["FF_DTG_AFD_4_3_SP_14_9",""],["FF_DTG_AFD_SAME",""],["FF_DTG_AFD_SP_4_3",""],["FF_EC_DEBLOCK",""],["FF_EC_FAVOR_INTER",""],["FF_EC_GUESS_MVS",""],["FF_FDEBUG_TS",""],["FF_IDCT_ALTIVEC",""],["FF_IDCT_ARM",""],["FF_IDCT_AUTO",""],["FF_IDCT_FAAN",""],["FF_IDCT_INT",""],["FF_IDCT_IPP",""],["FF_IDCT_SH4",""],["FF_IDCT_SIMPLE",""],["FF_IDCT_SIMPLEALPHA",""],["FF_IDCT_SIMPLEARM",""],["FF_IDCT_SIMPLEARMV5TE",""],["FF_IDCT_SIMPLEARMV6",""],["FF_IDCT_SIMPLEAUTO",""],["FF_IDCT_SIMPLEMMX",""],["FF_IDCT_SIMPLENEON",""],["FF_IDCT_SIMPLEVIS",""],["FF_IDCT_XVID",""],["FF_IDCT_XVIDMMX",""],["FF_INPUT_BUFFER_PADDING_SIZE",""],["FF_LAMBDA_MAX",""],["FF_LAMBDA_SCALE",""],["FF_LAMBDA_SHIFT",""],["FF_LEVEL_UNKNOWN",""],["FF_LOSS_ALPHA",""],["FF_LOSS_CHROMA",""],["FF_LOSS_COLORQUANT",""],["FF_LOSS_COLORSPACE",""],["FF_LOSS_DEPTH",""],["FF_LOSS_RESOLUTION",""],["FF_MAX_B_FRAMES",""],["FF_MB_DECISION_BITS",""],["FF_MB_DECISION_RD",""],["FF_MB_DECISION_SIMPLE",""],["FF_MIN_BUFFER_SIZE",""],["FF_PRED_LEFT",""],["FF_PRED_MEDIAN",""],["FF_PRED_PLANE",""],["FF_PROFILE_AAC_ELD",""],["FF_PROFILE_AAC_HE",""],["FF_PROFILE_AAC_HE_V2",""],["FF_PROFILE_AAC_LD",""],["FF_PROFILE_AAC_LOW",""],["FF_PROFILE_AAC_LTP",""],["FF_PROFILE_AAC_MAIN",""],["FF_PROFILE_AAC_SSR",""],["FF_PROFILE_DNXHD",""],["FF_PROFILE_DNXHR_444",""],["FF_PROFILE_DNXHR_HQ",""],["FF_PROFILE_DNXHR_HQX",""],["FF_PROFILE_DNXHR_LB",""],["FF_PROFILE_DNXHR_SQ",""],["FF_PROFILE_DTS",""],["FF_PROFILE_DTS_96_24",""],["FF_PROFILE_DTS_ES",""],["FF_PROFILE_DTS_EXPRESS",""],["FF_PROFILE_DTS_HD_HRA",""],["FF_PROFILE_DTS_HD_MA",""],["FF_PROFILE_H264_BASELINE",""],["FF_PROFILE_H264_CAVLC_444",""],["FF_PROFILE_H264_CONSTRAINED",""],["FF_PROFILE_H264_CONSTRAINED_BASELINE",""],["FF_PROFILE_H264_EXTENDED",""],["FF_PROFILE_H264_HIGH",""],["FF_PROFILE_H264_HIGH_10",""],["FF_PROFILE_H264_HIGH_10_INTRA",""],["FF_PROFILE_H264_HIGH_422",""],["FF_PROFILE_H264_HIGH_422_INTRA",""],["FF_PROFILE_H264_HIGH_444",""],["FF_PROFILE_H264_HIGH_444_INTRA",""],["FF_PROFILE_H264_HIGH_444_PREDICTIVE",""],["FF_PROFILE_H264_INTRA",""],["FF_PROFILE_H264_MAIN",""],["FF_PROFILE_H264_MULTIVIEW_HIGH",""],["FF_PROFILE_H264_STEREO_HIGH",""],["FF_PROFILE_HEVC_MAIN",""],["FF_PROFILE_HEVC_MAIN_10",""],["FF_PROFILE_HEVC_MAIN_STILL_PICTURE",""],["FF_PROFILE_HEVC_REXT",""],["FF_PROFILE_JPEG2000_CSTREAM_NO_RESTRICTION",""],["FF_PROFILE_JPEG2000_CSTREAM_RESTRICTION_0",""],["FF_PROFILE_JPEG2000_CSTREAM_RESTRICTION_1",""],["FF_PROFILE_JPEG2000_DCINEMA_2K",""],["FF_PROFILE_JPEG2000_DCINEMA_4K",""],["FF_PROFILE_MPEG2_422",""],["FF_PROFILE_MPEG2_AAC_HE",""],["FF_PROFILE_MPEG2_AAC_LOW",""],["FF_PROFILE_MPEG2_HIGH",""],["FF_PROFILE_MPEG2_MAIN",""],["FF_PROFILE_MPEG2_SIMPLE",""],["FF_PROFILE_MPEG2_SNR_SCALABLE",""],["FF_PROFILE_MPEG2_SS",""],["FF_PROFILE_MPEG4_ADVANCED_CODING",""],["FF_PROFILE_MPEG4_ADVANCED_CORE",""],["FF_PROFILE_MPEG4_ADVANCED_REAL_TIME",""],["FF_PROFILE_MPEG4_ADVANCED_SCALABLE_TEXTURE",""],["FF_PROFILE_MPEG4_ADVANCED_SIMPLE",""],["FF_PROFILE_MPEG4_BASIC_ANIMATED_TEXTURE",""],["FF_PROFILE_MPEG4_CORE",""],["FF_PROFILE_MPEG4_CORE_SCALABLE",""],["FF_PROFILE_MPEG4_HYBRID",""],["FF_PROFILE_MPEG4_MAIN",""],["FF_PROFILE_MPEG4_N_BIT",""],["FF_PROFILE_MPEG4_SCALABLE_TEXTURE",""],["FF_PROFILE_MPEG4_SIMPLE",""],["FF_PROFILE_MPEG4_SIMPLE_FACE_ANIMATION",""],["FF_PROFILE_MPEG4_SIMPLE_SCALABLE",""],["FF_PROFILE_MPEG4_SIMPLE_STUDIO",""],["FF_PROFILE_RESERVED",""],["FF_PROFILE_UNKNOWN",""],["FF_PROFILE_VC1_ADVANCED",""],["FF_PROFILE_VC1_COMPLEX",""],["FF_PROFILE_VC1_MAIN",""],["FF_PROFILE_VC1_SIMPLE",""],["FF_PROFILE_VP9_0",""],["FF_PROFILE_VP9_1",""],["FF_PROFILE_VP9_2",""],["FF_PROFILE_VP9_3",""],["FF_QP2LAMBDA",""],["FF_QSCALE_TYPE_H264",""],["FF_QSCALE_TYPE_MPEG1",""],["FF_QSCALE_TYPE_MPEG2",""],["FF_QSCALE_TYPE_VP56",""],["FF_QUALITY_SCALE",""],["FF_RC_STRATEGY_XVID",""],["FF_SUB_CHARENC_MODE_AUTOMATIC",""],["FF_SUB_CHARENC_MODE_DO_NOTHING",""],["FF_SUB_CHARENC_MODE_PRE_DECODER",""],["FF_SUB_TEXT_FMT_ASS",""],["FF_SUB_TEXT_FMT_ASS_WITH_TIMINGS",""],["FF_THREAD_FRAME",""],["FF_THREAD_SLICE",""],["NOPTS_VALUE",""],["SEEK_CUR",""],["SEEK_END",""],["SEEK_SET",""],["SWS_ACCURATE_RND",""],["SWS_AREA",""],["SWS_BICUBIC",""],["SWS_BICUBLIN",""],["SWS_BILINEAR",""],["SWS_BITEXACT",""],["SWS_CS_BT2020",""],["SWS_CS_DEFAULT",""],["SWS_CS_FCC",""],["SWS_CS_ITU601",""],["SWS_CS_ITU624",""],["SWS_CS_ITU709",""],["SWS_CS_SMPTE170M",""],["SWS_CS_SMPTE240M",""],["SWS_DIRECT_BGR",""],["SWS_ERROR_DIFFUSION",""],["SWS_FAST_BILINEAR",""],["SWS_FULL_CHR_H_INP",""],["SWS_FULL_CHR_H_INT",""],["SWS_GAUSS",""],["SWS_LANCZOS",""],["SWS_MAX_REDUCE_CUTOFF",""],["SWS_PARAM_DEFAULT",""],["SWS_POINT",""],["SWS_PRINT_INFO",""],["SWS_SINC",""],["SWS_SPLINE",""],["SWS_SRC_V_CHR_DROP_MASK",""],["SWS_SRC_V_CHR_DROP_SHIFT",""],["SWS_X",""]],"enum":[["AVActiveFormatDescription",""],["AVAudioServiceType",""],["AVChromaLocation","Location of chroma samples."],["AVClassCategory",""],["AVCodecID","Identify the syntax and semantics of the bitstream. The principle is roughly: Two decoders with the same ID can decode the same streams. Two encoders with the same ID can encode compatible streams. There may be slight deviations from the principle due to implementation details."],["AVColorPrimaries","Chromaticity coordinates of the source primaries."],["AVColorRange","MPEG vs JPEG YUV range."],["AVColorSpace","YUV colorspace type."],["AVColorTransferCharacteristic","Color Transfer Characteristic."],["AVDiscard","@ingroup lavc_decoding"],["AVDurationEstimationMethod","The duration of a video can be estimated through various ways, and this enum can be used to know how the duration was estimated."],["AVFieldOrder",""],["AVFrameSideDataType","@defgroup lavu_frame AVFrame @ingroup lavu_data"],["AVIODataMarkerType","Different data types that can be returned via the AVIO write_data_type callback."],["AVIODirEntryType","Directory entry types."],["AVLockOp","Lock operation used by lockmgr"],["AVMatrixEncoding",""],["AVMediaType","@addtogroup lavu_media Media Type @brief Media Type"],["AVPacketSideDataType","@defgroup lavc_packet AVPacket"],["AVPictureStructure","@defgroup lavc_parsing Frame parsing @{"],["AVPictureType","@} @} @defgroup lavu_picture Image related"],["AVPixelFormat","Pixel format."],["AVRounding","Rounding methods."],["AVSampleFormat","Audio sample formats"],["AVSideDataParamChangeFlags",""],["AVStreamParseType","@}"],["AVSubtitleType",""],["AVTimebaseSource",""],["idtype_t",""]],"fn":[["av_add_index_entry","Add an index entry into a sorted list. Update the entry if the list already contains it."],["av_add_q","Add two rationals. @param b First rational @param c Second rational @return b+c"],["av_add_stable","Add a value to a timestamp."],["av_append_packet","Read data and append it to the current content of the AVPacket. If pkt->size is 0 this is identical to av_get_packet. Note that this uses av_grow_packet and thus involves a realloc which is inefficient. Thus this function should only be used when there is no reasonable way to know (an upper bound of) the final size."],["av_apply_bitstream_filters",""],["av_audio_resample_init",""],["av_bitstream_filter_close","Release bitstream filter context."],["av_bitstream_filter_filter","Filter bitstream."],["av_bitstream_filter_init","Create and initialize a bitstream filter context given a bitstream filter name."],["av_bitstream_filter_next","If f is NULL, return the first registered bitstream filter, if f is non-NULL, return the next registered bitstream filter after f, or NULL if f is the last one."],["av_bprint_channel_layout","Append a description of a channel layout to a bprint buffer."],["av_bsf_alloc","Allocate a context for a given bitstream filter. The caller must fill in the context parameters as described in the documentation and then call av_bsf_init() before sending any data to the filter."],["av_bsf_free","Free a bitstream filter context and everything associated with it; write NULL into the supplied pointer."],["av_bsf_get_by_name","@return a bitstream filter with the specified name or NULL if no such bitstream filter exists."],["av_bsf_get_class","Get the AVClass for AVBSFContext. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options."],["av_bsf_get_null_filter","Get null/pass-through bitstream filter."],["av_bsf_init","Prepare the filter for use, after all the parameters and options have been set."],["av_bsf_list_alloc","Allocate empty list of bitstream filters. The list must be later freed by av_bsf_list_free() or finalized by av_bsf_list_finalize()."],["av_bsf_list_append","Append bitstream filter to the list of bitstream filters."],["av_bsf_list_append2","Construct new bitstream filter context given it's name and options and append it to the list of bitstream filters."],["av_bsf_list_finalize","Finalize list of bitstream filters."],["av_bsf_list_free","Free list of bitstream filters."],["av_bsf_list_parse_str","Parse string describing list of bitstream filters and create single @ref AVBSFContext describing the whole chain of bitstream filters. Resulting @ref AVBSFContext can be treated as any other @ref AVBSFContext freshly allocated by av_bsf_alloc()."],["av_bsf_next","Iterate over all registered bitstream filters."],["av_bsf_receive_packet","Retrieve a filtered packet."],["av_bsf_send_packet","Submit a packet for filtering."],["av_buffer_alloc","Allocate an AVBuffer of the given size using av_malloc()."],["av_buffer_allocz","Same as av_buffer_alloc(), except the returned buffer will be initialized to zero."],["av_buffer_create","Create an AVBuffer from an existing array."],["av_buffer_default_free","Default free callback, which calls av_free() on the buffer data. This function is meant to be passed to av_buffer_create(), not called directly."],["av_buffer_get_opaque","@return the opaque parameter set by av_buffer_create."],["av_buffer_get_ref_count",""],["av_buffer_is_writable","@return 1 if the caller may write to the data referred to by buf (which is true if and only if buf is the only reference to the underlying AVBuffer). Return 0 otherwise. A positive answer is valid until av_buffer_ref() is called on buf."],["av_buffer_make_writable","Create a writable reference from a given buffer reference, avoiding data copy if possible."],["av_buffer_pool_get","Allocate a new AVBuffer, reusing an old buffer from the pool when available. This function may be called simultaneously from multiple threads."],["av_buffer_pool_init","Allocate and initialize a buffer pool."],["av_buffer_pool_init2","Allocate and initialize a buffer pool with a more complex allocator."],["av_buffer_pool_uninit","Mark the pool as being available for freeing. It will actually be freed only once all the allocated buffers associated with the pool are released. Thus it is safe to call this function while some of the allocated buffers are still in use."],["av_buffer_realloc","Reallocate a given buffer."],["av_buffer_ref","Create a new reference to an AVBuffer."],["av_buffer_unref","Free a given reference and automatically free the buffer if there are no more references to it."],["av_calloc","Non-inlined equivalent of av_mallocz_array()."],["av_channel_layout_extract_channel","Get the channel with the given index in channel_layout."],["av_chroma_location_name","@return the name for provided chroma location or NULL if unknown."],["av_codec_get_chroma_intra_matrix",""],["av_codec_get_codec_descriptor",""],["av_codec_get_codec_properties",""],["av_codec_get_id","Get the AVCodecID for the given codec tag tag. If no codec id is found returns AV_CODEC_ID_NONE."],["av_codec_get_lowres",""],["av_codec_get_max_lowres",""],["av_codec_get_pkt_timebase",""],["av_codec_get_seek_preroll",""],["av_codec_get_tag","Get the codec tag for the given codec id id. If no codec tag is found returns 0."],["av_codec_get_tag2","Get the codec tag for the given codec id."],["av_codec_is_decoder","@return a non-zero number if codec is a decoder, zero otherwise"],["av_codec_is_encoder","@return a non-zero number if codec is an encoder, zero otherwise"],["av_codec_next","If c is NULL, returns the first registered codec, if c is non-NULL, returns the next registered codec after c, or NULL if c is the last one."],["av_codec_set_chroma_intra_matrix",""],["av_codec_set_codec_descriptor",""],["av_codec_set_lowres",""],["av_codec_set_pkt_timebase",""],["av_codec_set_seek_preroll",""],["av_color_primaries_name","@return the name for provided color primaries or NULL if unknown."],["av_color_range_name","@return the name for provided color range or NULL if unknown."],["av_color_space_name","@return the name for provided color space or NULL if unknown."],["av_color_transfer_name","@return the name for provided color transfer or NULL if unknown."],["av_compare_mod","Compare the remainders of two integer operands divided by a common divisor."],["av_compare_ts","Compare two timestamps each in its own time base."],["av_copy_packet","Copy packet, including contents"],["av_copy_packet_side_data","Copy packet side data"],["av_cpb_properties_alloc","Allocate a CPB properties structure and initialize its fields to default values."],["av_cpu_count","@return the number of logical CPU cores present."],["av_d2q","Convert a double precision floating point number to a rational."],["av_default_get_category",""],["av_default_item_name","Return the context name"],["av_demuxer_open",""],["av_dict_copy","Copy entries from one AVDictionary struct into another. @param dst pointer to a pointer to a AVDictionary struct. If *dst is NULL,            this function will allocate a struct for you and put it in *dst @param src pointer to source AVDictionary struct @param flags flags to use when setting entries in *dst @note metadata is read using the AV_DICT_IGNORE_SUFFIX flag @return 0 on success, negative AVERROR code on failure. If dst was allocated           by this function, callers should free the associated memory."],["av_dict_count","Get number of entries in dictionary."],["av_dict_free","Free all the memory allocated for an AVDictionary struct and all keys and values."],["av_dict_get","Get a dictionary entry with matching key."],["av_dict_get_string","Get dictionary entries as a string."],["av_dict_parse_string","Parse the key/value pairs list and add the parsed entries to a dictionary."],["av_dict_set","Set the given entry in *pm, overwriting an existing entry."],["av_dict_set_int","Convenience wrapper for av_dict_set that converts the value to a string and stores it."],["av_div_q","Divide one rational by another. @param b First rational @param c Second rational @return b/c"],["av_dump_format","Print detailed information about the input or output format, such as duration, bitrate, streams, container, programs, metadata, side data, codec and time base."],["av_dup_packet","@warning This is a hack - the packet memory allocation stuff is broken. The packet is allocated if it was not really allocated."],["av_dynarray2_add","Add an element of size `elem_size` to a dynamic array."],["av_dynarray_add","Add the pointer to an element to a dynamic array."],["av_dynarray_add_nofree","Add an element to a dynamic array."],["av_fast_malloc","Allocate a buffer, reusing the given one if large enough."],["av_fast_mallocz","Allocate and clear a buffer, reusing the given one if large enough."],["av_fast_padded_malloc","Same behaviour av_fast_malloc but the buffer has additional AV_INPUT_BUFFER_PADDING_SIZE at the end which will always be 0."],["av_fast_padded_mallocz","Same behaviour av_fast_padded_malloc except that buffer will always be 0-initialized after call."],["av_fast_realloc","Reallocate the given buffer if it is not large enough, otherwise do nothing."],["av_filename_number_test","Check whether filename actually is a numbered sequence generator."],["av_find_best_pix_fmt_of_2","Compute what kind of losses will occur when converting from one specific pixel format to another. When converting from one pixel format to another, information loss may occur. For example, when converting from RGB24 to GRAY, the color information will be lost. Similarly, other losses occur when converting from some formats to other formats. These losses can involve loss of chroma, but also loss of resolution, loss of color depth, loss due to the color space conversion, loss of the alpha bits or loss due to color quantization. av_get_fix_fmt_loss() informs you about the various types of losses which will occur when converting from one pixel format to another."],["av_find_best_stream","Find the \"best\" stream in the file. The best stream is determined according to various heuristics as the most likely to be what the user expects. If the decoder parameter is non-NULL, av_find_best_stream will find the default decoder for the stream's codec; streams for which no decoder can be found are ignored."],["av_find_default_stream_index",""],["av_find_input_format","Find AVInputFormat based on the short name of the input format."],["av_find_nearest_q_idx","Find the value in a list of rationals nearest a given reference rational."],["av_find_program_from_stream","Find the programs which belong to a given stream."],["av_fmt_ctx_get_duration_estimation_method","Returns the method used to set ctx->duration."],["av_fopen_utf8","Open a file using a UTF-8 filename. The API of this function matches POSIX fopen(), errors are returned through errno."],["av_force_cpu_flags","Disables cpu detection and forces the specified flags. -1 is a special case that disables forcing of specific flags."],["av_format_get_audio_codec",""],["av_format_get_control_message_cb",""],["av_format_get_data_codec",""],["av_format_get_metadata_header_padding",""],["av_format_get_opaque",""],["av_format_get_open_cb",""],["av_format_get_probe_score","Accessors for some AVFormatContext fields. These used to be provided for ABI compatibility, and do not need to be used anymore."],["av_format_get_subtitle_codec",""],["av_format_get_video_codec",""],["av_format_inject_global_side_data","This function will cause global side data to be injected in the next packet of each stream as well as after any subsequent seek."],["av_format_set_audio_codec",""],["av_format_set_control_message_cb",""],["av_format_set_data_codec",""],["av_format_set_metadata_header_padding",""],["av_format_set_opaque",""],["av_format_set_open_cb",""],["av_format_set_subtitle_codec",""],["av_format_set_video_codec",""],["av_fourcc_make_string","Fill the provided buffer with a string containing a FourCC (four-character code) representation."],["av_frame_alloc","Allocate an AVFrame and set its fields to default values.  The resulting struct must be freed using av_frame_free()."],["av_frame_clone","Create a new frame that references the same data as src."],["av_frame_copy","Copy the frame data from src to dst."],["av_frame_copy_props","Copy only \"metadata\" fields from src to dst."],["av_frame_free","Free the frame and any dynamically allocated objects in it, e.g. extended_data. If the frame is reference counted, it will be unreferenced first."],["av_frame_get_best_effort_timestamp","Accessors for some AVFrame fields. These used to be provided for ABI compatibility, and do not need to be used anymore."],["av_frame_get_buffer","Allocate new buffer(s) for audio or video data."],["av_frame_get_channel_layout",""],["av_frame_get_channels",""],["av_frame_get_color_range",""],["av_frame_get_colorspace",""],["av_frame_get_decode_error_flags",""],["av_frame_get_metadata",""],["av_frame_get_pkt_duration",""],["av_frame_get_pkt_pos",""],["av_frame_get_pkt_size",""],["av_frame_get_plane_buffer","Get the buffer reference a given data plane is stored in."],["av_frame_get_qp_table",""],["av_frame_get_sample_rate",""],["av_frame_get_side_data","@return a pointer to the side data of a given type on success, NULL if there is no side data with such type in this frame."],["av_frame_is_writable","Check if the frame data is writable."],["av_frame_make_writable","Ensure that the frame data is writable, avoiding data copy if possible."],["av_frame_move_ref","Move everything contained in src to dst and reset src."],["av_frame_new_side_data","Add a new side data to a frame."],["av_frame_ref","Set up a new reference to the data described by the source frame."],["av_frame_remove_side_data","If side data of the supplied type exists in the frame, free it and remove it from the frame."],["av_frame_set_best_effort_timestamp",""],["av_frame_set_channel_layout",""],["av_frame_set_channels",""],["av_frame_set_color_range",""],["av_frame_set_colorspace",""],["av_frame_set_decode_error_flags",""],["av_frame_set_metadata",""],["av_frame_set_pkt_duration",""],["av_frame_set_pkt_pos",""],["av_frame_set_pkt_size",""],["av_frame_set_qp_table",""],["av_frame_set_sample_rate",""],["av_frame_side_data_name","@return a string identifying the side data type"],["av_frame_unref","Unreference all the buffers referenced by frame and reset the frame fields."],["av_free","Free a memory block which has been allocated with a function of av_malloc() or av_realloc() family."],["av_free_packet","Free a packet."],["av_freep","Free a memory block which has been allocated with a function of av_malloc() or av_realloc() family, and set the pointer pointing to it to `NULL`."],["av_gcd","Compute the greatest common divisor of two integer operands."],["av_get_alt_sample_fmt","Return the planar<->packed alternative form of the given sample format, or AV_SAMPLE_FMT_NONE on error. If the passed sample_fmt is already in the requested planar/packed format, the format returned is the same as the input."],["av_get_audio_frame_duration","Return audio frame duration."],["av_get_audio_frame_duration2","This function is the same as av_get_audio_frame_duration(), except it works with AVCodecParameters instead of an AVCodecContext."],["av_get_bits_per_pixel","Return the number of bits per pixel used by the pixel format described by pixdesc. Note that this is not the same as the number of bits per sample."],["av_get_bits_per_sample","Return codec bits per sample."],["av_get_bytes_per_sample","Return number of bytes per sample."],["av_get_channel_description","Get the description of a given channel."],["av_get_channel_layout","Return a channel layout id that matches name, or 0 if no match is found."],["av_get_channel_layout_channel_index","Get the index of a channel in channel_layout."],["av_get_channel_layout_nb_channels","Return the number of channels in the channel layout."],["av_get_channel_layout_string","Return a description of a channel layout. If nb_channels is <= 0, it is guessed from the channel_layout."],["av_get_channel_name","Get the name of a given channel."],["av_get_codec_tag_string","Put a string representing the codec tag codec_tag in buf."],["av_get_colorspace_name","Get the name of a colorspace. @return a static string identifying the colorspace; can be NULL."],["av_get_cpu_flags","Return the flags which specify extensions supported by the CPU. The returned value is affected by av_force_cpu_flags() if that was used before. So av_get_cpu_flags() can easily be used in an application to detect the enabled cpu flags."],["av_get_default_channel_layout","Return default channel layout for a given number of channels."],["av_get_exact_bits_per_sample","Return codec bits per sample. Only return non-zero if the bits per sample is exactly correct, not an approximation."],["av_get_extended_channel_layout","Return a channel layout and the number of channels based on the specified name."],["av_get_frame_filename",""],["av_get_frame_filename2","Return in 'buf' the path with '%d' replaced by a number."],["av_get_media_type_string","Return a string describing the media_type enum, NULL if media_type is unknown."],["av_get_output_timestamp","Get timing information for the data currently output. The exact meaning of \"currently output\" depends on the format. It is mostly relevant for devices that have an internal buffer and/or work in real time. @param s          media file handle @param stream     stream in the media file @param[out] dts   DTS of the last packet output for the stream, in stream                   time_base units @param[out] wall  absolute time when that packet whas output,                   in microsecond @return  0 if OK, AVERROR(ENOSYS) if the format does not support it Note: some formats or devices may not allow to measure dts and wall atomically."],["av_get_packed_sample_fmt",""],["av_get_packet","Allocate and read the payload of a packet and initialize its fields with default values."],["av_get_padded_bits_per_pixel","Return the number of bits per pixel for the pixel format described by pixdesc, including any padding or unused bits."],["av_get_pcm_codec","Return the PCM codec associated with a sample format. @param be  endianness, 0 for little, 1 for big,            -1 (or anything else) for native @return  AV_CODEC_ID_PCM_* or AV_CODEC_ID_NONE"],["av_get_picture_type_char","Return a single letter to describe the given picture type pict_type."],["av_get_pix_fmt","Return the pixel format corresponding to name."],["av_get_pix_fmt_loss","Compute what kind of losses will occur when converting from one specific pixel format to another. When converting from one pixel format to another, information loss may occur. For example, when converting from RGB24 to GRAY, the color information will be lost. Similarly, other losses occur when converting from some formats to other formats. These losses can involve loss of chroma, but also loss of resolution, loss of color depth, loss due to the color space conversion, loss of the alpha bits or loss due to color quantization. av_get_fix_fmt_loss() informs you about the various types of losses which will occur when converting from one pixel format to another."],["av_get_pix_fmt_name","Return the short name for a pixel format, NULL in case pix_fmt is unknown."],["av_get_pix_fmt_string","Print in buf the string corresponding to the pixel format with number pix_fmt, or a header if pix_fmt is negative."],["av_get_planar_sample_fmt",""],["av_get_profile_name","Return a name for the specified profile, if available."],["av_get_sample_fmt","Return a sample format corresponding to name, or AV_SAMPLE_FMT_NONE on error."],["av_get_sample_fmt_name","Return the name of sample_fmt, or NULL if sample_fmt is not recognized."],["av_get_sample_fmt_string","Generate a string corresponding to the sample format with sample_fmt, or a header if sample_fmt is negative."],["av_get_standard_channel_layout","Get the value and name of a standard channel layout."],["av_get_time_base_q","Return the fractional representation of the internal time base."],["av_grow_packet","Increase packet size, correctly zeroing padding"],["av_guess_codec","Guess the codec ID based upon muxer and filename."],["av_guess_format","Return the output format in the list of registered output formats which best matches the provided parameters, or return NULL if there is no match."],["av_guess_frame_rate","Guess the frame rate, based on both the container and codec information."],["av_guess_sample_aspect_ratio","Guess the sample aspect ratio of a frame, based on both the stream and the frame aspect ratio."],["av_hex_dump","Send a nice hexadecimal dump of a buffer to the specified file stream."],["av_hex_dump_log","Send a nice hexadecimal dump of a buffer to the log."],["av_hwaccel_next","If hwaccel is NULL, returns the first registered hardware accelerator, if hwaccel is non-NULL, returns the next registered hardware accelerator after hwaccel, or NULL if hwaccel is the last one."],["av_iformat_next","If f is NULL, returns the first registered input format, if f is non-NULL, returns the next registered input format after f or NULL if f is the last one."],["av_image_alloc","Allocate an image with size w and h and pixel format pix_fmt, and fill pointers and linesizes accordingly. The allocated image buffer has to be freed by using av_freep(&pointers[0])."],["av_image_check_sar","Check if the given sample aspect ratio of an image is valid."],["av_image_check_size","Check if the given dimension of an image is valid, meaning that all bytes of the image can be addressed with a signed int."],["av_image_check_size2","Check if the given dimension of an image is valid, meaning that all bytes of a plane of an image with the specified pix_fmt can be addressed with a signed int."],["av_image_copy","Copy image in src_data to dst_data."],["av_image_copy_plane","Copy image plane from src to dst. That is, copy \"height\" number of lines of \"bytewidth\" bytes each. The first byte of each successive line is separated by *_linesize bytes."],["av_image_copy_to_buffer","Copy image data from an image into a buffer."],["av_image_copy_uc_from","Copy image data located in uncacheable (e.g. GPU mapped) memory. Where available, this function will use special functionality for reading from such memory, which may result in greatly improved performance compared to plain av_image_copy()."],["av_image_fill_arrays","Setup the data pointers and linesizes based on the specified image parameters and the provided array."],["av_image_fill_linesizes","Fill plane linesizes for an image with pixel format pix_fmt and width width."],["av_image_fill_max_pixsteps","Compute the max pixel step for each plane of an image with a format described by pixdesc."],["av_image_fill_pointers","Fill plane data pointers for an image with pixel format pix_fmt and height height."],["av_image_get_buffer_size","Return the size in bytes of the amount of data required to store an image with the given parameters."],["av_image_get_linesize","Compute the size of an image line with format pix_fmt and width width for the plane plane."],["av_index_search_timestamp","Get the index for a specific timestamp."],["av_init_packet","Initialize optional fields of a packet with default values."],["av_int_list_length_for_size","Compute the length of an integer list."],["av_interleaved_write_frame","Write a packet to an output media file ensuring correct interleaving."],["av_interleaved_write_uncoded_frame","Write an uncoded frame to an output media file."],["av_lockmgr_register","Register a user provided lock manager supporting the operations specified by AVLockOp. The \"mutex\" argument to the function points to a (void *) where the lockmgr should store/get a pointer to a user allocated mutex. It is NULL upon AV_LOCK_CREATE and equal to the value left by the last call for all other ops. If the lock manager is unable to perform the op then it should leave the mutex in the same state as when it was called and return a non-zero value. However, when called with AV_LOCK_DESTROY the mutex will always be assumed to have been successfully destroyed. If av_lockmgr_register succeeds it will return a non-negative value, if it fails it will return a negative value and destroy all mutex and unregister all callbacks. av_lockmgr_register is not thread-safe, it must be called from a single thread before any calls which make use of locking are used."],["av_log","Send the specified message to the log if the level is less than or equal to the current av_log_level. By default, all logging messages are sent to stderr. This behavior can be altered by setting a different logging callback function. @see av_log_set_callback"],["av_log2",""],["av_log2_16bit",""],["av_log_ask_for_sample","Log a generic warning message asking for a sample. This function is intended to be used internally by FFmpeg (libavcodec, libavformat, etc.) only, and would normally not be used by applications. @param[in] avc a pointer to an arbitrary struct of which the first field is a pointer to an AVClass struct @param[in] msg string containing an optional message, or NULL if no message @deprecated Use avpriv_request_sample() instead."],["av_log_default_callback","Default logging callback"],["av_log_format_line","Format a line of log the same way as the default callback. @param line          buffer to receive the formatted line @param line_size     size of the buffer @param print_prefix  used to store whether the prefix must be printed;                      must point to a persistent integer initially set to 1"],["av_log_format_line2","Format a line of log the same way as the default callback. @param line          buffer to receive the formatted line;                      may be NULL if line_size is 0 @param line_size     size of the buffer; at most line_size-1 characters will                      be written to the buffer, plus one null terminator @param print_prefix  used to store whether the prefix must be printed;                      must point to a persistent integer initially set to 1 @return Returns a negative value if an error occurred, otherwise returns         the number of characters that would have been written for a         sufficiently large buffer, not including the terminating null         character. If the return value is not less than line_size, it means         that the log message was truncated to fit the buffer."],["av_log_get_flags",""],["av_log_get_level","Get the current log level"],["av_log_missing_feature","Log a generic warning message about a missing feature. This function is intended to be used internally by FFmpeg (libavcodec, libavformat, etc.) only, and would normally not be used by applications. @param[in] avc a pointer to an arbitrary struct of which the first field is a pointer to an AVClass struct @param[in] feature string containing the name of the missing feature @param[in] want_sample indicates if samples are wanted which exhibit this feature. If want_sample is non-zero, additional verbiage will be added to the log message which tells the user how to report samples to the development mailing list. @deprecated Use avpriv_report_missing_feature() instead."],["av_log_set_callback","Set the logging callback"],["av_log_set_flags",""],["av_log_set_level","Set the log level"],["av_malloc","Allocate a memory block with alignment suitable for all memory accesses (including vectors if available on the CPU)."],["av_mallocz","Allocate a memory block with alignment suitable for all memory accesses (including vectors if available on the CPU) and zero all the bytes of the block."],["av_match_ext","Return a positive value if the given filename has one of the given extensions, 0 otherwise."],["av_max_alloc","Set the maximum size that may be allocated in one block."],["av_memcpy_backptr","Overlapping memcpy() implementation."],["av_memdup","Duplicate a buffer with av_malloc()."],["av_mul_q","Multiply two rationals. @param b First rational @param c Second rational @return b*c"],["av_nearer_q","Find which of the two rationals is closer to another rational."],["av_new_packet","Allocate the payload of a packet and initialize its fields with default values."],["av_new_program",""],["av_oformat_next","If f is NULL, returns the first registered output format, if f is non-NULL, returns the next registered output format after f or NULL if f is the last one."],["av_packet_add_side_data","Wrap an existing array as a packet side data."],["av_packet_alloc","Allocate an AVPacket and set its fields to default values.  The resulting struct must be freed using av_packet_free()."],["av_packet_clone","Create a new packet that references the same data as src."],["av_packet_copy_props","Copy only \"properties\" fields from src to dst."],["av_packet_free","Free the packet, if the packet is reference counted, it will be unreferenced first."],["av_packet_free_side_data","Convenience function to free all the side data stored. All the other fields stay untouched."],["av_packet_from_data","Initialize a reference-counted packet from av_malloc()ed data."],["av_packet_get_side_data","Get side information from packet."],["av_packet_merge_side_data",""],["av_packet_move_ref","Move every field in src to dst and reset src."],["av_packet_new_side_data","Allocate new information of a packet."],["av_packet_pack_dictionary","Pack a dictionary for use in side_data."],["av_packet_ref","Setup a new reference to the data described by a given packet"],["av_packet_rescale_ts","Convert valid timing fields (timestamps / durations) in a packet from one timebase to another. Timestamps with unknown values (AV_NOPTS_VALUE) will be ignored."],["av_packet_shrink_side_data","Shrink the already allocated side data buffer"],["av_packet_side_data_name",""],["av_packet_split_side_data",""],["av_packet_unpack_dictionary","Unpack a dictionary from side_data."],["av_packet_unref","Wipe the packet."],["av_parse_cpu_caps","Parse CPU caps from a string and update the given AV_CPU_* flags based on that."],["av_parse_cpu_flags","Parse CPU flags from a string."],["av_parser_change","@return 0 if the output buffer is a subset of the input, 1 if it is allocated and must be freed @deprecated use AVBitStreamFilter"],["av_parser_close",""],["av_parser_init",""],["av_parser_next",""],["av_parser_parse2",""],["av_picture_copy","@deprecated av_image_copy() instead."],["av_picture_crop","@deprecated unused"],["av_picture_pad","@deprecated unused"],["av_pix_fmt_count_planes","@return number of planes in pix_fmt, a negative AVERROR if pix_fmt is not a valid pixel format."],["av_pix_fmt_desc_get","@return a pixel format descriptor for provided pixel format or NULL if this pixel format is unknown."],["av_pix_fmt_desc_get_id","@return an AVPixelFormat id described by desc, or AV_PIX_FMT_NONE if desc is not a valid pointer to a pixel format descriptor."],["av_pix_fmt_desc_next","Iterate over all pixel format descriptors known to libavutil."],["av_pix_fmt_get_chroma_sub_sample","Utility function to access log2_chroma_w log2_chroma_h from the pixel format AVPixFmtDescriptor."],["av_pix_fmt_swap_endianness","Utility function to swap the endianness of a pixel format."],["av_pkt_dump2","Send a nice dump of a packet to the specified file stream."],["av_pkt_dump_log2","Send a nice dump of a packet to the log."],["av_probe_input_buffer","Like av_probe_input_buffer2() but returns 0 on success"],["av_probe_input_buffer2","Probe a bytestream to determine the input format. Each time a probe returns with a score that is too low, the probe buffer size is increased and another attempt is made. When the maximum probe size is reached, the input format with the highest score is returned."],["av_probe_input_format","Guess the file format."],["av_probe_input_format2","Guess the file format."],["av_probe_input_format3","Guess the file format."],["av_program_add_stream_index",""],["av_q2intfloat","Convert an AVRational to a IEEE 32-bit `float` expressed in fixed-point format."],["av_read_frame","Return the next frame of a stream. This function returns what is stored in the file, and does not validate that what is there are valid frames for the decoder. It will split what is stored in the file into frames and return one for each call. It will not omit invalid data between valid frames so as to give the decoder the maximum information possible for decoding."],["av_read_image_line","Read a line from an image, and write the values of the pixel format component c to dst."],["av_read_pause","Pause a network-based stream (e.g. RTSP stream)."],["av_read_play","Start playing a network-based stream (e.g. RTSP stream) at the current position."],["av_realloc","Allocate, reallocate, or free a block of memory."],["av_realloc_array","Allocate, reallocate, or free an array."],["av_realloc_f","Allocate, reallocate, or free a block of memory."],["av_reallocp","Allocate, reallocate, or free a block of memory through a pointer to a pointer."],["av_reallocp_array","Allocate, reallocate, or free an array through a pointer to a pointer."],["av_reduce","Reduce a fraction."],["av_register_all","Initialize libavformat and register all the muxers, demuxers and protocols. If you do not call this function, then you can select exactly which formats you want to support."],["av_register_bitstream_filter","Register a bitstream filter."],["av_register_codec_parser",""],["av_register_hwaccel","Register the hardware accelerator hwaccel."],["av_register_input_format",""],["av_register_output_format",""],["av_resample","Resample an array of samples using a previously configured context. @param src an array of unconsumed samples @param consumed the number of samples of src which have been consumed are returned here @param src_size the number of unconsumed samples available @param dst_size the amount of space in samples available in dst @param update_ctx If this is 0 then the context will not be modified, that way several channels can be resampled with the same context. @return the number of samples written in dst or -1 if an error occurred"],["av_resample_close",""],["av_resample_compensate","Compensate samplerate/timestamp drift. The compensation is done by changing the resampler parameters, so no audible clicks or similar distortions occur @param compensation_distance distance in output samples over which the compensation should be performed @param sample_delta number of output samples which should be output less"],["av_resample_init",""],["av_rescale","Rescale a 64-bit integer with rounding to nearest."],["av_rescale_delta","Rescale a timestamp while preserving known durations."],["av_rescale_q","Rescale a 64-bit integer by 2 rational numbers."],["av_rescale_q_rnd","Rescale a 64-bit integer by 2 rational numbers with specified rounding."],["av_rescale_rnd","Rescale a 64-bit integer with specified rounding."],["av_sample_fmt_is_planar","Check if the sample format is planar."],["av_samples_alloc","Allocate a samples buffer for nb_samples samples, and fill data pointers and linesize accordingly. The allocated samples buffer can be freed by using av_freep(&audio_data[0]) Allocated data will be initialized to silence."],["av_samples_alloc_array_and_samples","Allocate a data pointers array, samples buffer for nb_samples samples, and fill data pointers and linesize accordingly."],["av_samples_copy","Copy samples from src to dst."],["av_samples_fill_arrays","Fill plane data pointers and linesize for samples with sample format sample_fmt."],["av_samples_get_buffer_size","Get the required buffer size for the given audio parameters."],["av_samples_set_silence","Fill an audio buffer with silence."],["av_sdp_create","Generate an SDP for an RTP session."],["av_seek_frame","Seek to the keyframe at timestamp. 'timestamp' in 'stream_index'."],["av_set_cpu_flags_mask","Set a mask on flags returned by av_get_cpu_flags(). This function is mainly useful for testing. Please use av_force_cpu_flags() and av_get_cpu_flags() instead which are more flexible"],["av_shrink_packet","Reduce packet size, correctly zeroing padding"],["av_strdup","Duplicate a string."],["av_stream_add_side_data","Wrap an existing array as stream side data."],["av_stream_get_codec_timebase","Get the internal codec timebase from a stream."],["av_stream_get_end_pts","Returns the pts of the last muxed packet + its duration"],["av_stream_get_parser",""],["av_stream_get_r_frame_rate",""],["av_stream_get_recommended_encoder_configuration",""],["av_stream_get_side_data",""],["av_stream_new_side_data","Allocate new information from stream."],["av_stream_set_r_frame_rate",""],["av_stream_set_recommended_encoder_configuration",""],["av_strerror","Put a description of the AVERROR code errnum in errbuf. In case of failure the global variable errno is set to indicate the error. Even in case of failure av_strerror() will print a generic error message indicating the errnum provided to errbuf."],["av_strndup","Duplicate a substring of a string."],["av_sub_q","Subtract one rational from another. @param b First rational @param c Second rational @return b-c"],["av_url_split","Split a URL string into components."],["av_version_info","Return an informative version string. This usually is the actual release version number or a git commit description. This string has no fixed format and can change any time. It should never be parsed by code."],["av_vlog","Send the specified message to the log if the level is less than or equal to the current av_log_level. By default, all logging messages are sent to stderr. This behavior can be altered by setting a different logging callback function. @see av_log_set_callback"],["av_write_frame","Write a packet to an output media file."],["av_write_image_line","Write the values from src to the pixel format component c of an image line."],["av_write_trailer","Write the stream trailer to an output media file and free the file private data."],["av_write_uncoded_frame","Write an uncoded frame to an output media file."],["av_write_uncoded_frame_query","Test whether a muxer supports uncoded frame."],["av_xiphlacing","Encode extradata length to a buffer. Used by xiph codecs."],["avcodec_align_dimensions","Modify width and height values so that they will result in a memory buffer that is acceptable for the codec if you do not use any horizontal padding."],["avcodec_align_dimensions2","Modify width and height values so that they will result in a memory buffer that is acceptable for the codec if you also ensure that all line sizes are a multiple of the respective linesize_align[i]."],["avcodec_alloc_context3","Allocate an AVCodecContext and set its fields to default values. The resulting struct should be freed with avcodec_free_context()."],["avcodec_chroma_pos_to_enum","Converts swscale x/y chroma position to AVChromaLocation."],["avcodec_close","Close a given AVCodecContext and free all the data associated with it (but not the AVCodecContext itself)."],["avcodec_configuration","Return the libavcodec build-time configuration."],["avcodec_copy_context","Copy the settings of the source AVCodecContext into the destination AVCodecContext. The resulting destination codec context will be unopened, i.e. you are required to call avcodec_open2() before you can use this AVCodecContext to decode/encode video/audio data."],["avcodec_decode_audio4",""],["avcodec_decode_subtitle2","Decode a subtitle message. Return a negative value on error, otherwise return the number of bytes used. If no subtitle could be decompressed, got_sub_ptr is zero. Otherwise, the subtitle is stored in *sub. Note that AV_CODEC_CAP_DR1 is not available for subtitle codecs. This is for simplicity, because the performance difference is expect to be negligible and reusing a get_buffer written for video codecs would probably perform badly due to a potentially very different allocation pattern."],["avcodec_decode_video2","Decode the video frame of size avpkt->size from avpkt->data into picture. Some decoders may support multiple frames in a single AVPacket, such decoders would then just decode the first frame."],["avcodec_default_execute",""],["avcodec_default_execute2",""],["avcodec_default_get_buffer2","The default callback for AVCodecContext.get_buffer2(). It is made public so it can be called by custom get_buffer2() implementations for decoders without AV_CODEC_CAP_DR1 set."],["avcodec_default_get_format",""],["avcodec_descriptor_get","@return descriptor for given codec ID or NULL if no descriptor exists."],["avcodec_descriptor_get_by_name","@return codec descriptor with the given name or NULL if no such descriptor exists."],["avcodec_descriptor_next","Iterate over all codec descriptors known to libavcodec."],["avcodec_encode_audio2","Encode a frame of audio."],["avcodec_encode_subtitle",""],["avcodec_encode_video2","Encode a frame of video."],["avcodec_enum_to_chroma_pos","Converts AVChromaLocation to swscale x/y chroma position."],["avcodec_fill_audio_frame","Fill AVFrame audio data and linesize pointers."],["avcodec_find_best_pix_fmt2",""],["avcodec_find_best_pix_fmt_of_2","@deprecated see av_find_best_pix_fmt_of_2()"],["avcodec_find_best_pix_fmt_of_list","Find the best pixel format to convert to given a certain source pixel format.  When converting from one pixel format to another, information loss may occur.  For example, when converting from RGB24 to GRAY, the color information will be lost. Similarly, other losses occur when converting from some formats to other formats. avcodec_find_best_pix_fmt_of_2() searches which of the given pixel formats should be used to suffer the least amount of loss. The pixel formats from which it chooses one, are determined by the pix_fmt_list parameter."],["avcodec_find_decoder","Find a registered decoder with a matching codec ID."],["avcodec_find_decoder_by_name","Find a registered decoder with the specified name."],["avcodec_find_encoder","Find a registered encoder with a matching codec ID."],["avcodec_find_encoder_by_name","Find a registered encoder with the specified name."],["avcodec_flush_buffers","Reset the internal decoder state / flush internal buffers. Should be called e.g. when seeking or when switching to a different stream."],["avcodec_free_context","Free the codec context and everything associated with it and write NULL to the provided pointer."],["avcodec_get_chroma_sub_sample","Utility function to access log2_chroma_w log2_chroma_h from the pixel format AVPixFmtDescriptor."],["avcodec_get_class","Get the AVClass for AVCodecContext. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options."],["avcodec_get_context_defaults3","@deprecated This function should not be used, as closing and opening a codec context multiple time is not supported. A new codec context should be allocated for each new use."],["avcodec_get_edge_width","Return the amount of padding in pixels which the get_buffer callback must provide around the edge of the image for codecs which do not have the CODEC_FLAG_EMU_EDGE flag."],["avcodec_get_frame_class","Get the AVClass for AVFrame. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options."],["avcodec_get_name","Get the name of a codec. @return  a static string identifying the codec; never NULL"],["avcodec_get_pix_fmt_loss","@deprecated see av_get_pix_fmt_loss()"],["avcodec_get_subtitle_rect_class","Get the AVClass for AVSubtitleRect. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options."],["avcodec_get_type","Get the type of the given codec."],["avcodec_is_open","@return a positive value if s is open (i.e. avcodec_open2() was called on it with no corresponding avcodec_close()), 0 otherwise."],["avcodec_license","Return the libavcodec license."],["avcodec_open2","Initialize the AVCodecContext to use the given AVCodec. Prior to using this function the context has to be allocated with avcodec_alloc_context3()."],["avcodec_parameters_alloc","Allocate a new AVCodecParameters and set its fields to default values (unknown/invalid/0). The returned struct must be freed with avcodec_parameters_free()."],["avcodec_parameters_copy","Copy the contents of src to dst. Any allocated fields in dst are freed and replaced with newly allocated duplicates of the corresponding fields in src."],["avcodec_parameters_free","Free an AVCodecParameters instance and everything associated with it and write NULL to the supplied pointer."],["avcodec_parameters_from_context","Fill the parameters struct based on the values from the supplied codec context. Any allocated fields in par are freed and replaced with duplicates of the corresponding fields in codec."],["avcodec_parameters_to_context","Fill the codec context based on the values from the supplied codec parameters. Any allocated fields in codec that have a corresponding field in par are freed and replaced with duplicates of the corresponding field in par. Fields in codec that do not have a counterpart in par are not touched."],["avcodec_pix_fmt_to_codec_tag","Return a value representing the fourCC code associated to the pixel format pix_fmt, or 0 if no associated fourCC code can be found."],["avcodec_profile_name","Return a name for the specified profile, if available."],["avcodec_receive_frame","Return decoded output data from a decoder."],["avcodec_receive_packet","Read encoded data from the encoder."],["avcodec_register","Register the codec codec and initialize libavcodec."],["avcodec_register_all","Register all the codecs, parsers and bitstream filters which were enabled at configuration time. If you do not call this function you can select exactly which formats you want to support, by using the individual registration functions."],["avcodec_send_frame","Supply a raw video or audio frame to the encoder. Use avcodec_receive_packet() to retrieve buffered output packets."],["avcodec_send_packet","Supply raw packet data as input to a decoder."],["avcodec_set_dimensions","@deprecated this function is not supposed to be used from outside of lavc"],["avcodec_string",""],["avcodec_version","Return the LIBAVCODEC_VERSION_INT constant."],["avformat_alloc_context","Allocate an AVFormatContext. avformat_free_context() can be used to free the context and everything allocated by the framework within it."],["avformat_alloc_output_context2","Allocate an AVFormatContext for an output format. avformat_free_context() can be used to free the context and everything allocated by the framework within it."],["avformat_close_input","Close an opened input AVFormatContext. Free it and all its contents and set *s to NULL."],["avformat_configuration","Return the libavformat build-time configuration."],["avformat_find_stream_info","Read packets of a media file to get stream information. This is useful for file formats with no headers such as MPEG. This function also computes the real framerate in case of MPEG-2 repeat frame mode. The logical file position is not changed by this function; examined packets may be buffered for later processing."],["avformat_flush","Discard all internally buffered data. This can be useful when dealing with discontinuities in the byte stream. Generally works only with formats that can resync. This includes headerless formats like MPEG-TS/TS but should also work with NUT, Ogg and in a limited way AVI for example."],["avformat_free_context","Free an AVFormatContext and all its streams. @param s context to free"],["avformat_get_class","Get the AVClass for AVFormatContext. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options."],["avformat_get_mov_audio_tags","@return the table mapping MOV FourCCs for audio to AVCodecID."],["avformat_get_mov_video_tags","@return the table mapping MOV FourCCs for video to libavcodec AVCodecID."],["avformat_get_riff_audio_tags","@return the table mapping RIFF FourCCs for audio to AVCodecID."],["avformat_get_riff_video_tags","@defgroup riff_fourcc RIFF FourCCs @{ Get the tables mapping RIFF FourCCs to libavcodec AVCodecIDs. The tables are meant to be passed to av_codec_get_id()/av_codec_get_tag() as in the following code: @code uint32_t tag = MKTAG('H', '2', '6', '4'); const struct AVCodecTag *table[] = { avformat_get_riff_video_tags(), 0 }; enum AVCodecID id = av_codec_get_id(table, tag); @endcode @return the table mapping RIFF FourCCs for video to libavcodec AVCodecID."],["avformat_init_output","Allocate the stream private data and initialize the codec, but do not write the header. May optionally be used before avformat_write_header to initialize stream parameters before actually writing the header. If using this function, do not pass the same options to avformat_write_header."],["avformat_license","Return the libavformat license."],["avformat_match_stream_specifier","Check if the stream st contained in s is matched by the stream specifier spec."],["avformat_network_deinit","Undo the initialization done by avformat_network_init."],["avformat_network_init","Do global initialization of network components. This is optional, but recommended, since it avoids the overhead of implicitly doing the setup for each session."],["avformat_new_stream","Add a new stream to a media file."],["avformat_open_input","Open an input stream and read the header. The codecs are not opened. The stream must be closed with avformat_close_input()."],["avformat_query_codec","Test if the given container can store a codec."],["avformat_queue_attached_pictures",""],["avformat_seek_file","Seek to timestamp ts. Seeking will be done so that the point from which all active streams can be presented successfully will be closest to ts and within min/max_ts. Active streams are all streams that have AVStream.discard < AVDISCARD_ALL."],["avformat_transfer_internal_stream_timing_info","Transfer internal timing information from one stream to another."],["avformat_version","Return the LIBAVFORMAT_VERSION_INT constant."],["avformat_write_header","Allocate the stream private data and write the stream header to an output media file."],["avio_accept","Accept and allocate a client context on a server context. @param  s the server context @param  c the client context, must be unallocated @return   >= 0 on success or a negative value corresponding           to an AVERROR on failure"],["avio_alloc_context","Allocate and initialize an AVIOContext for buffered I/O. It must be later freed with av_free()."],["avio_check","Return AVIO_FLAG_* access flags corresponding to the access permissions of the resource in url, or a negative value corresponding to an AVERROR code in case of failure. The returned access flags are masked by the value in flags."],["avio_close","Close the resource accessed by the AVIOContext s and free it. This function can only be used if s was opened by avio_open()."],["avio_close_dir","Close directory."],["avio_close_dyn_buf","Return the written size and a pointer to the buffer. The buffer must be freed with av_free(). Padding of AV_INPUT_BUFFER_PADDING_SIZE is added to the buffer."],["avio_closep","Close the resource accessed by the AVIOContext *s, free it and set the pointer pointing to it to NULL. This function can only be used if s was opened by avio_open()."],["avio_enum_protocols","Iterate through names of available protocols."],["avio_feof","feof() equivalent for AVIOContext. @return non zero if and only if end of file"],["avio_find_protocol_name","Return the name of the protocol that will handle the passed URL."],["avio_flush","Force flushing of buffered data."],["avio_free_directory_entry","Free entry allocated by avio_read_dir()."],["avio_get_dyn_buf","Return the written size and a pointer to the buffer. The AVIOContext stream is left intact. The buffer must NOT be freed. No padding is added to the buffer."],["avio_get_str","Read a string from pb into buf. The reading will terminate when either a NULL character was encountered, maxlen bytes have been read, or nothing more can be read from pb. The result is guaranteed to be NULL-terminated, it will be truncated if buf is too small. Note that the string is not interpreted or validated in any way, it might get truncated in the middle of a sequence for multi-byte encodings."],["avio_get_str16be",""],["avio_get_str16le","Read a UTF-16 string from pb and convert it to UTF-8. The reading will terminate when either a null or invalid character was encountered or maxlen bytes have been read. @return number of bytes read (is always <= maxlen)"],["avio_handshake","Perform one step of the protocol handshake to accept a new client. This function must be called on a client returned by avio_accept() before using it as a read/write context. It is separate from avio_accept() because it may block. A step of the handshake is defined by places where the application may decide to change the proceedings. For example, on a protocol with a request header and a reply header, each one can constitute a step because the application may use the parameters from the request to change parameters in the reply; or each individual chunk of the request can constitute a step. If the handshake is already finished, avio_handshake() does nothing and returns 0 immediately."],["avio_open","Create and initialize a AVIOContext for accessing the resource indicated by url. @note When the resource indicated by url has been opened in read+write mode, the AVIOContext can be used only for writing."],["avio_open2","Create and initialize a AVIOContext for accessing the resource indicated by url. @note When the resource indicated by url has been opened in read+write mode, the AVIOContext can be used only for writing."],["avio_open_dir","Open directory for reading."],["avio_open_dyn_buf","Open a write only memory stream."],["avio_pause","Pause and resume playing - only meaningful if using a network streaming protocol (e.g. MMS)."],["avio_printf","@warning Writes up to 4 KiB per call "],["avio_put_str","Write a NULL-terminated string. @return number of bytes written."],["avio_put_str16be","Convert an UTF-8 string to UTF-16BE and write it. @param s the AVIOContext @param str NULL-terminated UTF-8 string"],["avio_put_str16le","Convert an UTF-8 string to UTF-16LE and write it. @param s the AVIOContext @param str NULL-terminated UTF-8 string"],["avio_r8","@name Functions for reading from AVIOContext @{"],["avio_rb16",""],["avio_rb24",""],["avio_rb32",""],["avio_rb64",""],["avio_read","Read size bytes from AVIOContext into buf. @return number of bytes read or AVERROR"],["avio_read_dir","Get next directory entry."],["avio_read_to_bprint","Read contents of h into print buffer, up to max_size bytes, or up to EOF."],["avio_rl16",""],["avio_rl24",""],["avio_rl32",""],["avio_rl64",""],["avio_seek","fseek() equivalent for AVIOContext. @return new position or AVERROR."],["avio_seek_time","Seek to a given timestamp relative to some component stream. Only meaningful if using a network streaming protocol (e.g. MMS.)."],["avio_size","Get the filesize. @return filesize or AVERROR"],["avio_skip","Skip given number of bytes forward @return new position or AVERROR."],["avio_w8",""],["avio_wb16",""],["avio_wb24",""],["avio_wb32",""],["avio_wb64",""],["avio_wl16",""],["avio_wl24",""],["avio_wl32",""],["avio_wl64",""],["avio_write",""],["avio_write_marker","Mark the written bytestream as a specific type."],["avpicture_alloc","@deprecated unused"],["avpicture_fill","@deprecated use av_image_fill_arrays() instead."],["avpicture_free","@deprecated unused"],["avpicture_get_size","@deprecated use av_image_get_buffer_size() instead."],["avpicture_layout","@deprecated use av_image_copy_to_buffer() instead."],["avpriv_frame_get_metadatap",""],["avpriv_io_delete","Delete a resource."],["avpriv_io_move","Move or rename a resource."],["avsubtitle_free","Free all allocated data in the given subtitle struct."],["avutil_configuration","Return the libavutil build-time configuration."],["avutil_license","Return the libavutil license."],["avutil_version","Return the LIBAVUTIL_VERSION_INT constant."],["sws_addVec",""],["sws_allocVec","Allocate and return an uninitialized vector with length coefficients."],["sws_alloc_context","Allocate an empty SwsContext. This must be filled and passed to sws_init_context(). For filling see AVOptions, options.c and sws_setColorspaceDetails()."],["sws_cloneVec",""],["sws_convVec",""],["sws_convertPalette8ToPacked24","Convert an 8-bit paletted frame into a frame with a color depth of 24 bits."],["sws_convertPalette8ToPacked32","Convert an 8-bit paletted frame into a frame with a color depth of 32 bits."],["sws_freeContext","Free the swscaler context swsContext. If swsContext is NULL, then does nothing."],["sws_freeFilter",""],["sws_freeVec",""],["sws_getCachedContext","Check if context can be reused, otherwise reallocate a new one."],["sws_getCoefficients","Return a pointer to yuv<->rgb coefficients for the given colorspace suitable for sws_setColorspaceDetails()."],["sws_getColorspaceDetails","@return -1 if not supported"],["sws_getConstVec",""],["sws_getContext","Allocate and return an SwsContext. You need it to perform scaling/conversion operations using sws_scale()."],["sws_getDefaultFilter",""],["sws_getGaussianVec","Return a normalized Gaussian curve used to filter stuff quality = 3 is high quality, lower is lower quality."],["sws_getIdentityVec",""],["sws_get_class","Get the AVClass for swsContext. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options."],["sws_init_context","Initialize the swscaler context sws_context."],["sws_isSupportedEndiannessConversion","@param[in]  pix_fmt the pixel format @return a positive value if an endianness conversion for pix_fmt is supported, 0 otherwise."],["sws_isSupportedInput","Return a positive value if pix_fmt is a supported input format, 0 otherwise."],["sws_isSupportedOutput","Return a positive value if pix_fmt is a supported output format, 0 otherwise."],["sws_normalizeVec","Scale all the coefficients of a so that their sum equals height."],["sws_printVec2",""],["sws_scale","Scale the image slice in srcSlice and put the resulting scaled slice in the image in dst. A slice is a sequence of consecutive rows in an image."],["sws_scaleVec","Scale all the coefficients of a by the scalar value."],["sws_setColorspaceDetails","@param dstRange flag indicating the while-black range of the output (1=jpeg / 0=mpeg) @param srcRange flag indicating the while-black range of the input (1=jpeg / 0=mpeg) @param table the yuv2rgb coefficients describing the output yuv space, normally ff_yuv2rgb_coeffs[x] @param inv_table the yuv2rgb coefficients describing the input yuv space, normally ff_yuv2rgb_coeffs[x] @param brightness 16.16 fixed point brightness correction @param contrast 16.16 fixed point contrast correction @param saturation 16.16 fixed point saturation correction @return -1 if not supported"],["sws_shiftVec",""],["sws_subVec",""],["swscale_configuration","Return the libswscale build-time configuration."],["swscale_license","Return the libswscale license."],["swscale_version","@defgroup libsws libswscale Color conversion and scaling library."]],"struct":[["AVBPrint",""],["AVBSFContext","The bitstream filter state."],["AVBSFInternal",""],["AVBSFList",""],["AVBitStreamFilter",""],["AVBitStreamFilterContext",""],["AVBuffer",""],["AVBufferPool",""],["AVBufferRef","A reference to a data buffer."],["AVCPBProperties","This structure describes the bitrate properties of an encoded bitstream. It roughly corresponds to a subset the VBV parameters for MPEG-2 or HRD parameters for H.264/HEVC."],["AVChapter",""],["AVClass","Describe the class of an AVClass context structure. That is an arbitrary struct of which the first field is a pointer to an AVClass struct (e.g. AVCodecContext, AVFormatContext etc.)."],["AVCodec","AVCodec."],["AVCodecContext","main external API structure. New fields can be added to the end with minor version bumps. Removal, reordering and changes to existing fields require a major version bump. You can use AVOptions (av_opt* / av_set/get*()) to access these fields from user applications. The name string for AVOptions options matches the associated command line parameter name and can be found in libavcodec/options_table.h The AVOption/command line parameter names differ in some cases from the C structure field names for historic reasons or brevity. sizeof(AVCodecContext) must not be used outside libav*."],["AVCodecDefault",""],["AVCodecDescriptor","This struct describes the properties of a single codec described by an AVCodecID. @see avcodec_descriptor_get()"],["AVCodecInternal",""],["AVCodecParameters","This struct describes the properties of an encoded stream."],["AVCodecParser",""],["AVCodecParserContext",""],["AVCodecTag",""],["AVComponentDescriptor",""],["AVDeviceCapabilitiesQuery",""],["AVDeviceInfoList",""],["AVDictionary",""],["AVDictionaryEntry",""],["AVFormatContext","Format I/O context. New fields can be added to the end with minor version bumps. Removal, reordering and changes to existing fields require a major version bump. sizeof(AVFormatContext) must not be used outside libav*, use avformat_alloc_context() to create an AVFormatContext."],["AVFormatInternal",""],["AVFrac","The exact value of the fractional number is: 'val + num / den'. num is assumed to be 0 <= num < den."],["AVFrame","This structure describes decoded (raw) audio or video data."],["AVFrameSideData","Structure to hold side data for an AVFrame."],["AVHWAccel","@defgroup lavc_hwaccel AVHWAccel @{"],["AVIOContext","Bytestream IO Context. New fields can be added to the end with minor version bumps. Removal, reordering and changes to existing fields require a major version bump. sizeof(AVIOContext) must not be used outside libav*."],["AVIODirContext",""],["AVIODirEntry","Describes single entry of the directory."],["AVIOInterruptCB","Callback for checking whether to abort blocking functions. AVERROR_EXIT is returned in this case by the interrupted function. During blocking operations, callback is called with opaque as parameter. If the callback returns 1, the blocking operation will be aborted."],["AVIndexEntry",""],["AVInputFormat","@addtogroup lavf_decoding @{"],["AVOption","a pointer to the first option specified in the class if any or NULL"],["AVOptionRanges",""],["AVOutputFormat","@addtogroup lavf_encoding @{"],["AVPacket","This structure stores compressed data. It is typically exported by demuxers and then passed as input to decoders, or received as output from encoders and then passed to muxers."],["AVPacketList",""],["AVPacketSideData",""],["AVPanScan","Pan Scan area. This specifies the area which should be displayed. Note there may be multiple such areas for one frame."],["AVPicture","Picture data structure."],["AVPixFmtDescriptor","Descriptor that unambiguously describes how the bits of a pixel are stored in the up to 4 data planes of an image. It also stores the subsampling factors and number of components."],["AVProbeData","This structure contains the data a format has to probe a file."],["AVProfile","AVProfile."],["AVProgram","New fields can be added to the end with minor version bumps. Removal, reordering and changes to existing fields require a major version bump. sizeof(AVProgram) must not be used outside libav*."],["AVRational","Rational number (pair of numerator and denominator)."],["AVResampleContext",""],["AVStream","Stream structure. New fields can be added to the end with minor version bumps. Removal, reordering and changes to existing fields require a major version bump. sizeof(AVStream) must not be used outside libav*."],["AVStreamInternal",""],["AVStream__bindgen_ty_1",""],["AVSubtitle",""],["AVSubtitleRect",""],["FFFrac",""],["MpegEncContext",""],["RcOverride","@ingroup lavc_encoding"],["ReSampleContext",""],["SwsContext",""],["SwsFilter",""],["SwsVector",""],["URLContext",""],["_G_fpos64_t",""],["_G_fpos_t",""],["_IO_FILE",""],["_IO_jump_t",""],["_IO_marker",""],["__BindgenUnionField",""],["__fsid_t",""],["__locale_data",""],["__locale_struct",""],["__mbstate_t",""],["__mbstate_t__bindgen_ty_1",""],["__pthread_internal_list",""],["__sigset_t",""],["__va_list_tag",""],["div_t",""],["imaxdiv_t",""],["ldiv_t",""],["lldiv_t",""],["pthread_attr_t",""],["pthread_barrier_t",""],["pthread_barrierattr_t",""],["pthread_cond_t",""],["pthread_cond_t__bindgen_ty_1",""],["pthread_condattr_t",""],["pthread_mutex_t",""],["pthread_mutex_t___pthread_mutex_s",""],["pthread_mutexattr_t",""],["pthread_rwlock_t",""],["pthread_rwlock_t__bindgen_ty_1",""],["pthread_rwlockattr_t",""]],"type":[["AVOpenCallback",""],["FILE",""],["_IO_lock_t",""],["__blkcnt64_t",""],["__blkcnt_t",""],["__blksize_t",""],["__builtin_va_list",""],["__caddr_t",""],["__clock_t",""],["__clockid_t",""],["__compar_fn_t",""],["__daddr_t",""],["__dev_t",""],["__fsblkcnt64_t",""],["__fsblkcnt_t",""],["__fsfilcnt64_t",""],["__fsfilcnt_t",""],["__fsword_t",""],["__gid_t",""],["__gwchar_t",""],["__id_t",""],["__ino64_t",""],["__ino_t",""],["__int16_t",""],["__int32_t",""],["__int64_t",""],["__int8_t",""],["__intptr_t",""],["__key_t",""],["__locale_t",""],["__loff_t",""],["__mode_t",""],["__nlink_t",""],["__off64_t",""],["__off_t",""],["__pid_t",""],["__pthread_list_t",""],["__qaddr_t",""],["__quad_t",""],["__rlim64_t",""],["__rlim_t",""],["__sig_atomic_t",""],["__socklen_t",""],["__ssize_t",""],["__suseconds_t",""],["__syscall_slong_t",""],["__syscall_ulong_t",""],["__time_t",""],["__timer_t",""],["__u_quad_t",""],["__uid_t",""],["__uint16_t",""],["__uint32_t",""],["__uint64_t",""],["__uint8_t",""],["__useconds_t",""],["av_format_control_message","Callback used by devices to communicate with application."],["blkcnt_t",""],["blksize_t",""],["caddr_t",""],["clock_t",""],["clockid_t",""],["daddr_t",""],["dev_t",""],["double_t",""],["float_t",""],["fpos_t",""],["fsblkcnt_t",""],["fsfilcnt_t",""],["fsid_t",""],["gid_t",""],["id_t",""],["ino_t",""],["int_fast16_t",""],["int_fast32_t",""],["int_fast64_t",""],["int_fast8_t",""],["int_least16_t",""],["int_least32_t",""],["int_least64_t",""],["int_least8_t",""],["intmax_t",""],["key_t",""],["locale_t",""],["loff_t",""],["mode_t",""],["nlink_t",""],["off_t",""],["pid_t",""],["pthread_key_t",""],["pthread_once_t",""],["pthread_spinlock_t",""],["pthread_t",""],["quad_t",""],["register_t",""],["sigset_t",""],["suseconds_t",""],["time_t",""],["timer_t",""],["u_int16_t",""],["u_int32_t",""],["u_int64_t",""],["u_int8_t",""],["u_quad_t",""],["uid_t",""],["uint_fast16_t",""],["uint_fast32_t",""],["uint_fast64_t",""],["uint_fast8_t",""],["uint_least16_t",""],["uint_least32_t",""],["uint_least64_t",""],["uint_least8_t",""],["uintmax_t",""],["va_list",""],["wchar_t",""]]});